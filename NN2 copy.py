from cgi import test
from pyrsistent import b
import scipy.io as sp
from numpy import shape
import numpy as np
from sklearn.preprocessing import MinMaxScaler, minmax_scale
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import pandas as pd
import matplotlib.pyplot as plt

######################################################################


df = pd.read_excel(io='Meteoroite_Impact_Regolith\Impact.xlsx', sheet_name='Regolith')
data=np.array(df)

######################################################################

# scaler = MinMaxScaler((0,1))
# scaler.fit(data[:,:2])
# Inputs = scaler.transform(data[:,:2])
# Outputs=data[:,2]

###########################################################################

output_col = 2 # Change between 2 and 3
output_title = ["","","Cratering Depth (cm)","Spalling Depth (cm)"]

Inputs =data[:,:2]
Outputs=data[:,output_col]


scaler = MinMaxScaler((0,1))
scaler.fit(Inputs)
Inputs = scaler.transform(Inputs)

#####################################################################################

def Split(a,b, test_size):
    x_train, x_test, y_train, y_test=train_test_split(a,b,test_size=test_size)
    return x_train, x_test, y_train, y_test


x_train, x_test, y_train, y_test = Split(Inputs,Outputs,0.2)

    
#############################################################################




if __name__=="__main__":
    

    
    # build model
    model=tf.keras.Sequential([
        tf.keras.layers.Dense(4,input_dim=2, activation="relu"),
        tf.keras.layers.Dense(20, activation="relu"),
        tf.keras.layers.Dense(20, activation="relu"),
        tf.keras.layers.Dense(1)
    ])
    
    # compile model
    optimiser=tf.keras.optimizers.Adam(learning_rate=0.002)
    model.compile(optimizer=optimiser, loss="MSE")
    
    # train model
    model.fit(x_train, y_train, epochs=1800,verbose=1)
    
    # evaluate model
    print("\nModel evaluation:")
    model.evaluate(x_test, y_test, verbose=1)

    
  ####################################################################################  
    
    def R_squared(y, y_pred):
        residual = tf.reduce_sum(tf.square(tf.subtract(y, y_pred)))
        total = tf.reduce_sum(tf.square(tf.subtract(y, tf.reduce_mean(y))))
        r2 = tf.subtract(1.0, tf.div(residual, total))
        return r2


    predictions_test = model.predict(x_test)
    predictions_train = model.predict(x_train)
    
    test_num = int(np.ceil((0.2 * len(Inputs))))
    train_num = len(Inputs) - test_num

    Comparison_test=np.zeros((test_num,2))
    Comparison_test[:,0]=predictions_test[:,0]
    Comparison_test[:,1]=y_test
    aa=r2_score(y_test,predictions_test)
    bb=r2_score(y_train,predictions_train)
    

    Comparison_train=np.zeros((train_num,2))
    Comparison_train[:,0]=predictions_train[:,0]
    Comparison_train[:,1]=y_train

    print('r2_test:',aa)
    print('r2_train:',bb)
    # print("poop")
    # print(x_test)
    
    # print(Comparison)

    def depth_diam_graph(x_input, y_input, scaler, title):
        x = scaler.inverse_transform(x_input)
        new = np.append(x, y_input, axis=1)
        new = new[np.argsort(new[:, 0])]

        data = pd.DataFrame(new, columns = ['velocity', 'diameter', 'prediction', 'train'])

        for name, data in data.groupby('diameter'):
            plt.plot(data['velocity'], data['prediction'], label=name, marker='.')

        plt.xlabel('Velocity')
        plt.ylabel(title)
        plt.legend(bbox_to_anchor=(1.0, 1.0))
        plt.grid()
        plt.show()
        return
    
    def power_graph(x_input, y_input, scaler, title):
        x = scaler.inverse_transform(x_input)
        new = np.append(x, y_input, axis=1)
        new = new[np.argsort(new[:, 0])]
        a = new[:,1]**3
        b = new[:,0]**2
        power_col = a*b
        print(power_col)
        new = np.append(new,power_col[:,None], axis=1)

        data = pd.DataFrame(new, columns = ['velocity', 'diameter', 'prediction', 'train', 'power'])

        for name, data in data.groupby('diameter'):
            plt.plot(data['power'], data['prediction'], label=name, marker='.')

        plt.xlabel('power')
        plt.ylabel(title)
        plt.legend(bbox_to_anchor=(1.0, 1.0))
        plt.grid()
        plt.show()
        return

    # depth_diam_graph(x_test, Comparison_test, scaler, output_title[output_col]) # change between test and train data
    # power_graph(x_test, Comparison_test, scaler, output_title[output_col]) # change between test and train data

    # x_train = scaler.inverse_transform(x_train)

    # new = np.append(x_train, son, axis=1)
    # new = new[np.argsort(new[:, 0])]
    # # new = new[np.argsort(new[:, 1])]
    # print(new)
    # data = pd.DataFrame(new, columns = ['velocity', 'diameter', 'prediction', 'train'])

    # for name, data in data.groupby('diameter'):
    #     plt.plot(data['velocity'], data['prediction'], label=name, marker='.')

    # plt.xlabel('Velocity')
    # plt.ylabel(output_title[output_col])
    # plt.legend(bbox_to_anchor=(1.0, 1.0))
    # plt.grid()
    # plt.show()



    # print(Inputs)
    
    # def graph_prep(x_input, y_input, scaler):
    #     x = scaler.inverse_transform(x_input)










